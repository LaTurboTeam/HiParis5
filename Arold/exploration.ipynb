{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET = \"atoubert-ensae\"\n",
    "FILE_KEY_S3 = \"X_train_Hi5.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/Hackathon Hiparis/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    x_train = pd.read_csv(file_in, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = x_train.sample(n=10_000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = train_sample.columns[train_sample.isna().all()]\n",
    "print(\"Colonnes contenant uniquement des NaN :\", nan_columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_sample.loc[:, train_sample.isna().sum() <= 8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Étape 1 : Préparation des données\n",
    "# Filtrer les colonnes numériques\n",
    "train_sample_numeric = train_sample.select_dtypes(include=['number'])\n",
    "\n",
    "# Remplir les valeurs manquantes\n",
    "train_sample_numeric = train_sample_numeric.fillna(train_sample_numeric.mean())\n",
    "\n",
    "# Standardiser les données\n",
    "scaler = StandardScaler()\n",
    "train_sample_scaled = scaler.fit_transform(train_sample_numeric)\n",
    "\n",
    "# Étape 2 : Effectuer la PCA\n",
    "pca = PCA(n_components=5)  # Choisissez le nombre de composantes principales\n",
    "train_sample_pca = pca.fit_transform(train_sample_scaled)\n",
    "\n",
    "# Transformer en DataFrame pour une visualisation facile\n",
    "train_sample_pca_df = pd.DataFrame(\n",
    "    train_sample_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(train_sample_pca.shape[1])]\n",
    ")\n",
    "\n",
    "# Étape 3 : Tracer une heatmap des composantes principales\n",
    "sns.heatmap(train_sample_pca_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Heatmap des composantes principales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.iloc[1268326, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = train_sample.select_dtypes(include=['category', 'object'])\n",
    "categorical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['piezo_groundwater_level_category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = {col: train_sample[col].nunique() for col in categorical_data}\n",
    "\n",
    "# Étape 3 : Trouver la colonne avec le plus grand nombre de classes\n",
    "max_classes_col = max(unique_counts, key=unique_counts.get)\n",
    "max_classes_value = unique_counts[max_classes_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_classes_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "for proportion_nan_prct in [19]:\n",
    "    new_df = cp.deepcopy(x_train)\n",
    "    for col in new_df.columns:\n",
    "        if new_df[col].isnull().sum() * 100 / len(x_train) > proportion_nan_prct:\n",
    "            new_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=new_df\n",
    "categorical_data = df.select_dtypes(include=[\"object\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "for col in categorical_columns:\n",
    "    unique_classes = df[col].unique()  # Récupère les classes uniques\n",
    "    print(f\"Variable '{col}': {unique_classes[:5]}\")  # Affiche un extrait (5 premières classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x_train\n",
    "\n",
    "# Étape 1 : Convertir en type datetime\n",
    "df[\"piezo_station_update_date\"] = pd.to_datetime(df[\"piezo_station_update_date\"], errors=\"coerce\")\n",
    "\n",
    "# Étape 2 : Extraire les mois\n",
    "df[\"month\"] = df[\"piezo_station_update_date\"].dt.month\n",
    "\n",
    "# Étape 3 : Définir les saisons\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Hiver\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Printemps\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Été\"\n",
    "    elif month in [9, 10, 11]:\n",
    "        return \"Automne\"\n",
    "\n",
    "df[\"season\"] = df[\"month\"].apply(get_season)\n",
    "\n",
    "# Étape 4 : Compter les occurrences par saison\n",
    "season_counts = df[\"season\"].value_counts()\n",
    "print(season_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"piezo_station_update_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"atoubert-ensae\"\n",
    "FILE_KEY_S3 = \"X_test_Hi5.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/Hackathon Hiparis/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    x_test = pd.read_csv(file_in, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"piezo_measurement_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x_train\n",
    "df['piezo_measurement_date'] = pd.to_datetime(df['piezo_measurement_date'])\n",
    "\n",
    "# Créer la colonne 'saison' en fonction du mois\n",
    "df['saison'] = df['piezo_measurement_date'].dt.month.map({\n",
    "    1: 'Hiver', 2: 'Hiver', 12: 'Hiver',\n",
    "    3: 'Printemps', 4: 'Printemps', 5: 'Printemps',\n",
    "    6: 'Été', 7: 'Été', 8: 'Été',\n",
    "    9: 'Automne', 10: 'Automne', 11: 'Automne'\n",
    "})\n",
    "\n",
    "# Compter le nombre d'observations par saison\n",
    "count_par_saison = df.groupby('saison').size()\n",
    "\n",
    "print(count_par_saison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"piezo_measurement_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"piezo_measurement_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"piezo_station_update_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x_train\n",
    "\n",
    "df['mois'] = pd.to_datetime(df['ezo_station_update_date'], format='%a %b %d %H:%M:%S %Z %Y').dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2 : Extraire les mois\n",
    "df[\"month\"] = df[\"piezo_station_update_date\"].dt.month\n",
    "\n",
    "# Étape 3 : Définir les saisons\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Hiver\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Printemps\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Été\"\n",
    "    elif month in [9, 10, 11]:\n",
    "        return \"Automne\"\n",
    "\n",
    "df[\"season\"] = df[\"month\"].apply(get_season)\n",
    "\n",
    "# Étape 4 : Compter les occurrences par saison\n",
    "season_counts = df[\"season\"].value_counts()\n",
    "print(season_counts)\n",
    "df[\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x_test\n",
    "df['piezo_measurement_date'] = pd.to_datetime(df['piezo_measurement_date'])\n",
    "\n",
    "# Créer la colonne 'saison' en fonction du mois\n",
    "df['saison'] = df['piezo_measurement_date'].dt.month.map({\n",
    "    1: 'Hiver', 2: 'Hiver', 12: 'Hiver',\n",
    "    3: 'Printemps', 4: 'Printemps', 5: 'Printemps',\n",
    "    6: 'Été', 7: 'Été', 8: 'Été',\n",
    "    9: 'Automne', 10: 'Automne', 11: 'Automne'\n",
    "})\n",
    "\n",
    "# Compter le nombre d'observations par saison\n",
    "count_par_saison = df.groupby('saison').size()\n",
    "\n",
    "print(count_par_saison)\n",
    "x_test[\"piezo_measurement_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[\"piezo_measurement_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['piezo_measurement_date'].drop_duplicates().head(1000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
